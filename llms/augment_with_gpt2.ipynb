{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x12c438c10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration\n",
    "model_name = \"sdadas/polish-gpt2-medium\"\n",
    "random_seed = 42\n",
    "\n",
    "# Set seed for reproducibility\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_half(text):\n",
    "    half_length = len(text) // 2\n",
    "\n",
    "    # Szukanie najbliższego separatora zdania przed połową tekstu\n",
    "    match = re.search(r'[.!?]\\s', text[:half_length][::-1])  # Przeszukiwanie od końca połowy\n",
    "    if match:\n",
    "        end_idx = half_length - match.start()  # Indeks końca zdania\n",
    "        return text[:end_idx].strip()\n",
    "    \n",
    "    # Jeśli brak separatora zdania, szukaj końca pełnego słowa\n",
    "    words = text[:half_length].rsplit(' ', 1)\n",
    "    return words[0].strip() if len(words) > 1 else text[:half_length].strip()\n",
    "\n",
    "\n",
    "# Funkcja przycinająca do końca ostatniego zdania\n",
    "def truncate_to_sentence_end(text):\n",
    "    # Dopasowujemy wszystkie pełne zdania\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    # Zwracamy tekst do ostatniego pełnego zdania\n",
    "    return ' '.join(sentences[:-1]) if len(sentences) > 1 else text\n",
    "\n",
    "\n",
    "def generate_fixed_length_completion(text, augmentation_factor=1, temperature=0.7, top_p=0.9, top_k=50, buffor=10):\n",
    "    completions = []\n",
    "    \n",
    "    text_tokens = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "    original_token_count = len(text_tokens[0])  # Liczba tokenów w oryginalnym tekście\n",
    "\n",
    "    prompt = get_clean_half(text)\n",
    "    prompt_tokens = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    prompt_token_count = len(prompt_tokens[0])  # Liczba tokenów w promptu\n",
    "\n",
    "    # Obliczenie maksymalnej liczby tokenów do wygenerowania\n",
    "    max_tokens_to_generate = original_token_count - prompt_token_count\n",
    "\n",
    "    attention_mask = torch.ones_like(prompt_tokens)\n",
    "    \n",
    "    for _ in range(augmentation_factor):\n",
    "        generated_ids = model.generate(\n",
    "            prompt_tokens,\n",
    "            attention_mask = attention_mask,\n",
    "            max_length=prompt_token_count + max_tokens_to_generate + buffor,  # Całkowity limit tokenów\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            do_sample=True,\n",
    "            num_return_sequences=1\n",
    "        )\n",
    "\n",
    "        generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        continuation = generated_text[len(prompt):].strip()\n",
    "        continuation = truncate_to_sentence_end(continuation)\n",
    "        completions.append(continuation)\n",
    "    \n",
    "    return completions\n",
    "\n",
    "\n",
    "# Funkcja augmentacji całego zbioru danych przez dokańczanie o dokładnej długości\n",
    "def augment_dataset_with_gpt2(df, text_column=\"text\", label_column=\"label\", augmentation_factor=1, temperature=0.7, top_p=0.9, top_k=50):\n",
    "    augmented_rows = []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Augmenting dataset\", unit=\"row\"):\n",
    "        original_text = row[text_column]\n",
    "        label = row[label_column]\n",
    "\n",
    "        completions = generate_fixed_length_completion(\n",
    "            original_text,\n",
    "            augmentation_factor=augmentation_factor,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k\n",
    "        )\n",
    "        augmented_rows.append({text_column: original_text, label_column: label})\n",
    "        for completion in completions:\n",
    "            prompt = get_clean_half(original_text)\n",
    "            augmented_text = prompt + \" \" + completion\n",
    "            augmented_rows.append({text_column: augmented_text, label_column: label})\n",
    "\n",
    "    return pd.DataFrame(augmented_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces_before_punctuation(text):\n",
    "    # Usuwanie spacji przed kropkami i przecinkami\n",
    "    return re.sub(r'\\s+(?=[.,])', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting dataset: 100%|██████████| 300/300 [09:09<00:00,  1.83s/row]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented dataset saved to 'augmented_texts.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"all_texts.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "df['text'] = df['text'].apply(remove_spaces_before_punctuation)\n",
    "\n",
    "augmented_df = augment_dataset_with_gpt2(\n",
    "    df, \n",
    "    augmentation_factor=2,\n",
    "    temperature=0.9,\n",
    "    top_p=0.9,\n",
    "    top_k=50\n",
    ")\n",
    "\n",
    "augmented_df.to_csv(\"augmented_texts_gpt2.csv\", index=False)\n",
    "print(\"Augmented dataset saved to 'augmented_texts.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lakier roweru bardzo kiepskiej jakości, robią ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lakier roweru bardzo kiepskiej jakości, robią ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lakier roweru bardzo kiepskiej jakości, robią ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nie jestem zadowolony z zakupu. Przede wszystk...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nie jestem zadowolony z zakupu. Przede wszystk...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ten router to porażka, gdyż nie jest w stanie ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Chyba spodziewała m się czegoś więcej, po kosm...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Chyba spodziewała m się czegoś więcej, po kosm...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Chyba spodziewała m się czegoś więcej, po kosm...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Zanim wybrała m Lumie 640 szukała m opinii, al...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text     label\n",
       "0   Lakier roweru bardzo kiepskiej jakości, robią ...  Negative\n",
       "1   Lakier roweru bardzo kiepskiej jakości, robią ...  Negative\n",
       "2   Lakier roweru bardzo kiepskiej jakości, robią ...  Negative\n",
       "3   Nie jestem zadowolony z zakupu. Przede wszystk...  Negative\n",
       "4   Nie jestem zadowolony z zakupu. Przede wszystk...  Negative\n",
       "..                                                ...       ...\n",
       "95  Ten router to porażka, gdyż nie jest w stanie ...  Negative\n",
       "96  Chyba spodziewała m się czegoś więcej, po kosm...   Neutral\n",
       "97  Chyba spodziewała m się czegoś więcej, po kosm...   Neutral\n",
       "98  Chyba spodziewała m się czegoś więcej, po kosm...   Neutral\n",
       "99  Zanim wybrała m Lumie 640 szukała m opinii, al...  Negative\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_df.head(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
